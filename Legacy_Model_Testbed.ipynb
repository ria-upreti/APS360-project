{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Constants"
      ],
      "metadata": {
        "id": "KibS8wPkZyl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading"
      ],
      "metadata": {
        "id": "lseH8HE5Us81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VGyMibX7aLvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb2b8d7-bcb2-4e4d-d4ec-7690295d549a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LANGUAGES = [\"en\", \"de\", \"nl\", \"sv-SE\", \"da\"]\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 20\n",
        "TRAIN_BATCH = 100\n",
        "VAL_BATCH = 0\n",
        "SAMPLE_RATE = 48000\n",
        "OPTIMIZER = torch.optim.Adam\n",
        "LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
        "\n",
        "# Constants related to the MFCC processing\n",
        "# the number of samples per fft\n",
        "N_FFT = 2048\n",
        "# the amount of transform to shift\n",
        "HOP_LENGTH = 512\n",
        "# The number of coefficient we extract\n",
        "N_MFCC = 13"
      ],
      "metadata": {
        "id": "mwcVX2wFWyy8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Processing"
      ],
      "metadata": {
        "id": "fVqohc6HSxV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from glob import glob # list out files in directory -> reading wave files\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd # play files\n",
        "\n",
        "from itertools import cycle # colours and gimiks"
      ],
      "metadata": {
        "id": "XpIwtX0RS15s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "T2rbl8V_TChV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import random"
      ],
      "metadata": {
        "id": "9-1u9L9mTB-a"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "aiRpXsylZoC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# linking hugging face account\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pLqETfMgs6vk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add50088-c054-4b5e-e822-f525aed5b1d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Sneed` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Sneed`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(languages, train_batch, val_batch):\n",
        "  train_data = []\n",
        "  val_data = []\n",
        "\n",
        "  train_audio = []\n",
        "  train_labels = []\n",
        "  train_sr = []\n",
        "  val_audio = []\n",
        "  val_labels = []\n",
        "  val_sr = []\n",
        "\n",
        "  one_hot = F.one_hot(torch.tensor([0, 1, 2, 3, 4]), num_classes=len(languages))\n",
        "\n",
        "  for i in range(len(one_hot)):\n",
        "    one_hot[i] = one_hot[i].to(dtype=torch.float)\n",
        "\n",
        "  for i in range(len(languages)):\n",
        "    random_seed = random.randrange(1,100)\n",
        "    # Load common voice 17 dataset training set with streaming, and enabling custom code (necessary to load dataset correctly)\n",
        "    train_set = load_dataset(\"mozilla-foundation/common_voice_17_0\", languages[i], split=\"train\", streaming=True, trust_remote_code=True)\n",
        "    train_data.append(train_set.shuffle(buffer_size=train_batch, seed=random_seed))\n",
        "    val_set = load_dataset(\"mozilla-foundation/common_voice_17_0\", languages[i], split=\"validation\", streaming=True, trust_remote_code=True)\n",
        "    val_data.append(val_set.shuffle(buffer_size=val_batch, seed=random_seed))\n",
        "\n",
        "    it = iter(train_data[i])\n",
        "    it2 = iter(val_data[i])\n",
        "\n",
        "    for j in range(train_batch):\n",
        "      train_item = next(it)\n",
        "\n",
        "      if train_item:\n",
        "        train_audio.append(train_item['audio']['array'])\n",
        "        train_sr.append(train_item['audio']['sampling_rate'])\n",
        "        train_labels.append(one_hot[i])\n",
        "\n",
        "    for j in range(val_batch):\n",
        "      val_item = next(it2)\n",
        "\n",
        "      if val_item:\n",
        "        val_audio.append(val_item['audio']['array'])\n",
        "        val_sr.append(val_item['audio']['sampling_rate'])\n",
        "        val_labels.append(one_hot[i])\n",
        "\n",
        "\n",
        "    print(f\"Loaded {languages[i]}\")\n",
        "\n",
        "  return train_audio, train_labels, train_sr, val_audio, val_labels, val_sr"
      ],
      "metadata": {
        "id": "kcxGewtCt1YQ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_audio, train_labels, train_sr, val_audio, val_labels, val_sr = load_data(LANGUAGES, TRAIN_BATCH, VAL_BATCH)"
      ],
      "metadata": {
        "id": "A-xEGTzsyPY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ebdbc90-f48d-408e-98b3-f8c14023d830"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 1101170it [00:20, 54898.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 589100it [00:11, 53546.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 34898it [00:00, 67459.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded nl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 7744it [00:00, 36730.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded sv-SE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 3484it [00:00, 26111.30it/s]\n",
            "Exception ignored from cffi callback <function SoundFile._init_virtual_io.<locals>.vio_read at 0x7f8d2da79120>:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/soundfile.py\", line 1290, in vio_read\n",
            "    @_ffi.callback(\"sf_vio_read\")\n",
            "\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded da\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "V-rmiEypZrQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing audio\n",
        "\n",
        "def process_batch(audio_data, sample_rates, batch_size):\n",
        "  audio_processed = []\n",
        "\n",
        "  for i in range(batch_size):\n",
        "    # Resample\n",
        "    audio_resampled = librosa.resample(audio_data[i], orig_sr = sample_rates[i], target_sr = SAMPLE_RATE)\n",
        "\n",
        "    # Trimming decibels\n",
        "    audio_trimmed, _ = librosa.effects.trim(audio_resampled, top_db=80)\n",
        "\n",
        "    audio_length = 49000 * 7\n",
        "    if len(audio_trimmed) > audio_length:\n",
        "      audio_trimmed = audio_trimmed[:audio_length]\n",
        "\n",
        "    elif len(audio_trimmed) < audio_length:\n",
        "      padding = audio_length - len(audio_trimmed)\n",
        "      audio_trimmed = np.pad(audio_trimmed, (0, padding), mode='constant')\n",
        "\n",
        "    audio_trimmed = librosa.feature.mfcc(y = np.abs(audio_trimmed), sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mfcc=N_MFCC)\n",
        "\n",
        "    audio_processed.append(audio_trimmed)\n",
        "\n",
        "  return audio_processed"
      ],
      "metadata": {
        "id": "mxFlPmh3HiLb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib import cm\n",
        "\n",
        "TEST_INDEX = 1\n",
        "\n",
        "MFCC_data = process_batch(train_audio, train_sr, TRAIN_BATCH)\n",
        "\n",
        "D = librosa.amplitude_to_db(np.abs(MFCC_data[TEST_INDEX]), ref=np.max)\n",
        "img = librosa.display.specshow(D, y_axis='linear', x_axis='time', sr=SAMPLE_RATE)\n",
        "\n",
        "print(MFCC_data[TEST_INDEX].shape)"
      ],
      "metadata": {
        "id": "ydd64wXst82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "73ce1d9f-0e76-4035-b2aa-37017cf3c860"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_audio' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-20fd7eaf37bf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTEST_INDEX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mMFCC_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_BATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamplitude_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMFCC_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTEST_INDEX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_audio' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, audios, labels, sample_rates, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mfcc=N_MFCC, transform=None):\n",
        "        \"\"\"\n",
        "        audios: list of raw audio arrays\n",
        "        labels: list of labels\n",
        "        \"\"\"\n",
        "        self.audios = audios\n",
        "        self.labels = labels\n",
        "        self.sample_rates = sample_rates\n",
        "        self.n_fft = n_fft\n",
        "        self.hop_length = hop_length\n",
        "        self.n_mfcc = n_mfcc\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audios)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio = self.audios[idx]\n",
        "        label = self.labels[idx]\n",
        "        sr = self.sample_rates[idx]\n",
        "\n",
        "        audio_length = SAMPLE_RATE*5\n",
        "\n",
        "        # Resample\n",
        "        audio_resampled = librosa.resample(audio, orig_sr = sr, target_sr = SAMPLE_RATE)\n",
        "\n",
        "        # Trimming decibels\n",
        "        audio_trimmed, _ = librosa.effects.trim(audio_resampled, top_db=80)\n",
        "\n",
        "        # if audio too long trim down length (sr = 49000, so 3 sec)\n",
        "        if len(audio_trimmed) > audio_length:\n",
        "          audio_trimmed = audio_trimmed[:audio_length]\n",
        "\n",
        "        # if audio too short, add padding\n",
        "        elif len(audio_trimmed) < audio_length:\n",
        "          padding = audio_length - len(audio_trimmed)\n",
        "          audio_trimmed = np.pad(audio_trimmed, (0, padding), mode='constant')\n",
        "\n",
        "        # Calculate MFCCs for the trimmed audio\n",
        "        mfcc = librosa.feature.mfcc(y = np.abs(audio_trimmed), sr=SAMPLE_RATE, n_fft=self.n_fft, hop_length=self.hop_length, n_mfcc=self.n_mfcc)\n",
        "        mfcc = torch.tensor(mfcc, dtype=torch.float)\n",
        "\n",
        "        return mfcc, label"
      ],
      "metadata": {
        "id": "qgaDPrt1VTkx"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vk6k4O1zzYUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_dataset = AudioDataset(train_audio, train_labels, train_sr)\n",
        "train_loader = DataLoader(audio_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "ZMRya2RSQtDy"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Model"
      ],
      "metadata": {
        "id": "9y5V7V3rZvFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.c1 = nn.Sequential(\n",
        "      nn.Conv1d(\n",
        "        in_channels=13,\n",
        "        out_channels=32,\n",
        "        kernel_size=3,\n",
        "        stride=1,\n",
        "        padding=2,\n",
        "      ),\n",
        "      nn.BatchNorm1d(32),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2),\n",
        "      nn.Dropout(p=0.2)\n",
        "    )\n",
        "\n",
        "    self.c2 = nn.Sequential(\n",
        "      nn.Conv1d(\n",
        "        in_channels=16,\n",
        "        out_channels=64,\n",
        "        kernel_size=3,\n",
        "        stride=1,\n",
        "        padding=2\n",
        "      ),\n",
        "      nn.BatchNorm1d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2),\n",
        "      nn.Dropout(p=0.2)\n",
        "    )\n",
        "\n",
        "    self.c3 = nn.Sequential(\n",
        "      nn.Conv1d(\n",
        "        in_channels=32,\n",
        "        out_channels=128,\n",
        "        kernel_size=3,\n",
        "        stride=1,\n",
        "        padding=2\n",
        "      ),\n",
        "      nn.BatchNorm1d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2),\n",
        "      nn.Dropout(p=0.2)\n",
        "    )\n",
        "\n",
        "    self.global_max = nn.MaxPool2d(kernel_size=2)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear = nn.Linear(1344, len(LANGUAGES)) # BATCH_SIZE or other params\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, input):\n",
        "    x = self.c1(input)\n",
        "    x = self.c2(x)\n",
        "    x = self.c3(x)\n",
        "    x = self.global_max(x)\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear(x)\n",
        "    predictions = self.softmax(logits)\n",
        "    return logits, predictions"
      ],
      "metadata": {
        "id": "vei5rbFQa7RJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "avfuq0xQaoYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YJ5UjvQhyABD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "d1738168-fb60-42a6-a074-2ad788a8b3e9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_result():\n",
        "  save_dir = \"/content/drive/My Drive/training_results\"\n",
        "  os.makedirs(save_dir, exist_ok=True)\n",
        "  # np.savetxt(f\"{save_dir}/{model_path}_train_err.csv\", train_err)\n",
        "\n",
        "\n",
        "def save_weight(net, model_code):\n",
        "  \"\"\"model code will be a string code we assigned to each model\"\"\"\n",
        "  weight_dir = \"/content/drive/My Drive/model_weights\"\n",
        "  os.makedirs(weight_dir, exist_ok=True)\n",
        "\n",
        "  model_path = os.path.join(weight_dir, model_code)\n",
        "  torch.save(net.state_dict(), f\"{model_path}.pth\")\n",
        "\n",
        "\n",
        "def load_weight(net, model_code):\n",
        "  \"\"\"model code will be a string code we assigned to each model\"\"\"\n",
        "  weight_dir = \"/content/drive/My Drive/model_weights\"\n",
        "  model_path = os.path.join(weight_dir, model_code)\n",
        "\n",
        "  net.load_state_dict(torch.load(f\"{model_path}.pth\"))\n",
        "  net.eval()\n",
        "  return net"
      ],
      "metadata": {
        "id": "tWfyi7JtyDI9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, device, optimizer, loss_function, num_epochs):\n",
        "  start_time = time.time()\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for data, label in data_loader:\n",
        "      logits, predictions = model(data)\n",
        "      loss = loss_function(logits, label.to(dtype=torch.float))\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    print(f\"Epoch #{epoch} | Loss: {loss.item()}\")\n",
        "\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(f\"Time elapsed: {elapsed_time:.4f} seconds\")\n",
        "\n",
        "def test_accuracy_old(model, data_loader, device, optimizer, loss_function, num_epochs):\n",
        "  start_time = time.time()\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for data, label in data_loader:\n",
        "      logits, predictions = model(data)\n",
        "      loss = loss_function(logits, label.to(dtype=torch.float))\n",
        "\n",
        "    print(f\"Epoch #{epoch} | Loss: {loss.item()}\")\n",
        "\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(f\"Time elapsed: {elapsed_time:.4f} seconds\")\n",
        "\n",
        "\n",
        "def test_accuracy(model, data_loader, device, optimizer, loss_function, num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for data, label in data_loader:\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            logits, predictions = model(data)\n",
        "            loss = loss_function(logits, label.to(dtype=torch.float))\n",
        "            epoch_loss += loss.item() * data.size(0)\n",
        "\n",
        "            pred_classes = torch.argmax(predictions, dim=1)\n",
        "            true_classes = torch.argmax(label, dim=1)\n",
        "\n",
        "            correct += torch.eq(pred_classes, true_classes).sum().item()\n",
        "\n",
        "            total += label.size(0)\n",
        "\n",
        "        avg_loss = epoch_loss / total\n",
        "        accuracy = correct / total * 100\n",
        "        print(f\"Epoch #{epoch+1} | Loss: {avg_loss:.4f} | Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Time elapsed: {elapsed_time:.4f} seconds\")"
      ],
      "metadata": {
        "id": "0gO0K21ta7sG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = ConvNetwork()\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train(cnn, train_loader, DEVICE, optimizer, loss_function, NUM_EPOCHS)\n",
        "\n",
        "save_weight(cnn, \"Placeholder\")"
      ],
      "metadata": {
        "id": "1O7j-TPTyH4y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "f9468cce-75f5-4aad-cfa6-66c6659c43c8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a5b626c7ffff>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msave_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-8dae7b452266>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, device, optimizer, loss_function, num_epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = ConvNetwork()\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=LEARNING_RATE)\n",
        "load_weight(cnn, \"cnn_test_1\")\n",
        "\n",
        "# test_accuracy(cnn, train_loader, DEVICE, optimizer, loss_function, 1)\n",
        "train_audio, train_labels, train_sr, val_audio, val_labels, val_sr = load_data(LANGUAGES, TRAIN_BATCH, VAL_BATCH)\n",
        "audio_dataset = AudioDataset(train_audio, train_labels, train_sr)\n",
        "train_loader = DataLoader(audio_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_accuracy(cnn, train_loader, DEVICE, optimizer, loss_function, 1)\n",
        "\n",
        "train_audio, train_labels, train_sr, val_audio, val_labels, val_sr = load_data(LANGUAGES, TRAIN_BATCH, VAL_BATCH)\n",
        "audio_dataset = AudioDataset(train_audio, train_labels, train_sr)\n",
        "train_loader = DataLoader(audio_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_accuracy(cnn, train_loader, DEVICE, optimizer, loss_function, 1)\n",
        "\n",
        "train_audio, train_labels, train_sr, val_audio, val_labels, val_sr = load_data(LANGUAGES, TRAIN_BATCH, VAL_BATCH)\n",
        "audio_dataset = AudioDataset(train_audio, train_labels, train_sr)\n",
        "train_loader = DataLoader(audio_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_accuracy(cnn, train_loader, DEVICE, optimizer, loss_function, 1)\n",
        "\n",
        "train_audio, train_labels, train_sr, val_audio, val_labels, val_sr = load_data(LANGUAGES, TRAIN_BATCH, VAL_BATCH)\n",
        "audio_dataset = AudioDataset(train_audio, train_labels, train_sr)\n",
        "train_loader = DataLoader(audio_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_accuracy(cnn, train_loader, DEVICE, optimizer, loss_function, 1)\n",
        "\n",
        "train_audio, train_labels, train_sr, val_audio, val_labels, val_sr = load_data(LANGUAGES, TRAIN_BATCH, VAL_BATCH)\n",
        "audio_dataset = AudioDataset(train_audio, train_labels, train_sr)\n",
        "train_loader = DataLoader(audio_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_accuracy(cnn, train_loader, DEVICE, optimizer, loss_function, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TELMiBo8b5sM",
        "outputId": "a6ad2b69-8069-485c-8304-abc27f93d68b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-dd8243e4ee4a>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(f\"{model_path}.pth\"))\n",
            "Reading metadata...: 1101170it [00:18, 59452.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 589100it [00:12, 47126.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 34898it [00:00, 61409.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded nl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 7744it [00:01, 6881.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded sv-SE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 3484it [00:00, 25758.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded da\n",
            "Epoch #1 | Loss: 0.5542 | Accuracy: 79.40%\n",
            "Time elapsed: 45.6363 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 1101170it [00:18, 58839.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 589100it [00:09, 59928.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 34898it [00:00, 68365.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded nl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 7744it [00:00, 44515.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded sv-SE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 3484it [00:00, 29142.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded da\n",
            "Epoch #1 | Loss: 0.7725 | Accuracy: 68.20%\n",
            "Time elapsed: 49.1997 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 1101170it [00:18, 58934.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 589100it [00:10, 58383.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 34898it [00:00, 48584.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded nl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 7744it [00:00, 22470.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded sv-SE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 3484it [00:00, 31083.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded da\n",
            "Epoch #1 | Loss: 0.5353 | Accuracy: 72.00%\n",
            "Time elapsed: 47.0952 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 1101170it [00:19, 56554.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 589100it [00:10, 54613.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 34898it [00:00, 64501.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded nl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 7744it [00:00, 11521.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded sv-SE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 3484it [00:00, 22867.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded da\n",
            "Epoch #1 | Loss: 0.4643 | Accuracy: 86.40%\n",
            "Time elapsed: 45.2568 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 1101170it [00:17, 61235.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 589100it [00:10, 54180.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 34898it [00:00, 46457.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded nl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 7744it [00:00, 39352.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded sv-SE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 3484it [00:00, 30182.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded da\n",
            "Epoch #1 | Loss: 0.7375 | Accuracy: 70.40%\n",
            "Time elapsed: 46.7276 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNetwork_2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.c1 = nn.Sequential(\n",
        "      nn.Conv2d(\n",
        "        in_channels=1,\n",
        "        out_channels=32,\n",
        "        kernel_size=3,\n",
        "        stride=1,\n",
        "        padding=2,\n",
        "      ),\n",
        "      nn.BatchNorm2d(32),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2),\n",
        "      nn.Dropout(p=0.2)\n",
        "    )\n",
        "\n",
        "    self.c2 = nn.Sequential(\n",
        "      nn.Conv2d(\n",
        "        in_channels=32,\n",
        "        out_channels=64,\n",
        "        kernel_size=3,\n",
        "        stride=1,\n",
        "        padding=2\n",
        "      ),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2),\n",
        "      nn.Dropout(p=0.2)\n",
        "    )\n",
        "\n",
        "    self.c3 = nn.Sequential(\n",
        "      nn.Conv2d(\n",
        "        in_channels=64,\n",
        "        out_channels=128,\n",
        "        kernel_size=3,\n",
        "        stride=1,\n",
        "        padding=2\n",
        "      ),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2),\n",
        "      nn.Dropout(p=0.2)\n",
        "    )\n",
        "\n",
        "    self.global_max = nn.MaxPool2d(kernel_size=2)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear = nn.Linear(3840, len(LANGUAGES)) # BATCH_SIZE or other params\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, input):\n",
        "    input = input.unsqueeze(1)\n",
        "    input = input.squeeze(0)\n",
        "    x = self.c1(input)\n",
        "    x = self.c2(x)\n",
        "    x = self.c3(x)\n",
        "    x = self.global_max(x)\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear(x)\n",
        "    predictions = self.softmax(logits)\n",
        "    return logits, predictions"
      ],
      "metadata": {
        "id": "muTXjhAL0sqN"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = ConvNetwork_2()\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_audio, train_labels, train_sr, val_audio, val_labels, val_sr = load_data(LANGUAGES, TRAIN_BATCH, VAL_BATCH)\n",
        "audio_dataset = AudioDataset(train_audio, train_labels, train_sr)\n",
        "train_loader = DataLoader(audio_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "for i in range(1, 21):\n",
        "  name = \"cnn_test_2_epoch_\" + str(i)\n",
        "  load_weight(cnn, name)\n",
        "  test_accuracy(cnn, train_loader, DEVICE, optimizer, loss_function, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bXSe787zOv2",
        "outputId": "e49542ad-5c94-40b0-e685-91ac4c039f35"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 1101170it [00:17, 62206.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 589100it [00:08, 68827.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 34898it [00:00, 42719.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded nl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 7744it [00:00, 44559.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded sv-SE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 3484it [00:00, 29489.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded da\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-dd8243e4ee4a>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(f\"{model_path}.pth\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #1 | Loss: 2.3915 | Accuracy: 35.60%\n",
            "Time elapsed: 43.4324 seconds\n",
            "Epoch #1 | Loss: 1.5724 | Accuracy: 32.20%\n",
            "Time elapsed: 43.8623 seconds\n",
            "Epoch #1 | Loss: 1.4882 | Accuracy: 24.40%\n",
            "Time elapsed: 43.0753 seconds\n",
            "Epoch #1 | Loss: 1.4285 | Accuracy: 31.40%\n",
            "Time elapsed: 44.8217 seconds\n",
            "Epoch #1 | Loss: 1.4025 | Accuracy: 41.00%\n",
            "Time elapsed: 44.4776 seconds\n",
            "Epoch #1 | Loss: 1.3951 | Accuracy: 38.20%\n",
            "Time elapsed: 47.4758 seconds\n",
            "Epoch #1 | Loss: 1.4038 | Accuracy: 39.60%\n",
            "Time elapsed: 44.6774 seconds\n",
            "Epoch #1 | Loss: 1.4037 | Accuracy: 34.60%\n",
            "Time elapsed: 43.4356 seconds\n",
            "Epoch #1 | Loss: 1.3276 | Accuracy: 36.00%\n",
            "Time elapsed: 44.5422 seconds\n",
            "Epoch #1 | Loss: 1.2436 | Accuracy: 43.60%\n",
            "Time elapsed: 45.0891 seconds\n",
            "Epoch #1 | Loss: 1.1931 | Accuracy: 46.40%\n",
            "Time elapsed: 42.6359 seconds\n",
            "Epoch #1 | Loss: 1.2307 | Accuracy: 49.20%\n",
            "Time elapsed: 42.3193 seconds\n",
            "Epoch #1 | Loss: 1.1192 | Accuracy: 51.80%\n",
            "Time elapsed: 44.6080 seconds\n",
            "Epoch #1 | Loss: 1.2257 | Accuracy: 57.00%\n",
            "Time elapsed: 42.1483 seconds\n",
            "Epoch #1 | Loss: 1.0483 | Accuracy: 52.40%\n",
            "Time elapsed: 42.8867 seconds\n",
            "Epoch #1 | Loss: 0.9654 | Accuracy: 64.00%\n",
            "Time elapsed: 44.6750 seconds\n",
            "Epoch #1 | Loss: 1.0541 | Accuracy: 55.40%\n",
            "Time elapsed: 43.2671 seconds\n",
            "Epoch #1 | Loss: 0.9212 | Accuracy: 60.40%\n",
            "Time elapsed: 44.6096 seconds\n",
            "Epoch #1 | Loss: 0.9158 | Accuracy: 60.20%\n",
            "Time elapsed: 42.8891 seconds\n",
            "Epoch #1 | Loss: 1.1073 | Accuracy: 60.40%\n",
            "Time elapsed: 42.7349 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = ConvNetwork_2()\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=LEARNING_RATE)\n",
        "name = \"cnn_test_2_epoch_20\"\n",
        "load_weight(cnn, name)\n",
        "\n",
        "train_audio, train_labels, train_sr, val_audio, val_labels, val_sr = load_data(LANGUAGES, TRAIN_BATCH, VAL_BATCH)\n",
        "audio_dataset = AudioDataset(train_audio, train_labels, train_sr)\n",
        "train_loader = DataLoader(audio_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_accuracy(cnn, train_loader, DEVICE, optimizer, loss_function, 1)\n",
        "\n",
        "train_audio, train_labels, train_sr, val_audio, val_labels, val_sr = load_data(LANGUAGES, TRAIN_BATCH, VAL_BATCH)\n",
        "audio_dataset = AudioDataset(train_audio, train_labels, train_sr)\n",
        "train_loader = DataLoader(audio_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_accuracy(cnn, train_loader, DEVICE, optimizer, loss_function, 1)\n",
        "\n",
        "train_audio, train_labels, train_sr, val_audio, val_labels, val_sr = load_data(LANGUAGES, TRAIN_BATCH, VAL_BATCH)\n",
        "audio_dataset = AudioDataset(train_audio, train_labels, train_sr)\n",
        "train_loader = DataLoader(audio_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_accuracy(cnn, train_loader, DEVICE, optimizer, loss_function, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev1qUEqt6BBJ",
        "outputId": "8cc3c482-4699-43df-fced-36508a400214"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-dd8243e4ee4a>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(f\"{model_path}.pth\"))\n",
            "Reading metadata...: 1101170it [00:17, 62380.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 589100it [00:10, 58878.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 34898it [00:00, 67409.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded nl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 7744it [00:00, 12752.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded sv-SE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 3484it [00:00, 13559.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded da\n",
            "Epoch #1 | Loss: 0.9949 | Accuracy: 57.00%\n",
            "Time elapsed: 44.9910 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 1101170it [00:17, 61510.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 589100it [00:10, 57719.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 34898it [00:00, 45526.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded nl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 7744it [00:00, 29898.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded sv-SE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 3484it [00:00, 28689.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded da\n",
            "Epoch #1 | Loss: 1.0520 | Accuracy: 59.20%\n",
            "Time elapsed: 43.7125 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 1101170it [00:17, 62320.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 589100it [00:10, 54999.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded de\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 34898it [00:00, 47267.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded nl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 7744it [00:00, 36281.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded sv-SE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 3484it [00:00, 35879.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded da\n",
            "Epoch #1 | Loss: 0.9829 | Accuracy: 61.40%\n",
            "Time elapsed: 46.0831 seconds\n"
          ]
        }
      ]
    }
  ]
}